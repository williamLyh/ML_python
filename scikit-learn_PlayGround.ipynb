{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn\n",
    "====\n",
    "Tools for data analysis. <br>\n",
    "Documents:https://scikit-learn.org/stable/\n",
    "\n",
    "## Classfication\n",
    "1. SVM\n",
    "2. Nearest neighbour\n",
    "3. Random Forest\n",
    "\n",
    "## Regression\n",
    "1. SVR \n",
    "2. Ridge regression\n",
    "3. Lasso\n",
    "\n",
    "## Clustering\n",
    "1. k-Meanings\n",
    "2. spectrul clustering \n",
    "3. mean-shift\n",
    "\n",
    "## Dimensionality reduction\n",
    "1. PCA\n",
    "2. feature selection\n",
    "3. non-negative matrix factorization\n",
    "\n",
    "## Model Selection\n",
    "\n",
    "## Preprocessing\n",
    "1. pre-processing\n",
    "2. feature selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification: SVM\n",
    "1. SVC & NuSVC\n",
    "2. LinearSVB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "# Two Classes example\n",
    "X = np.array([[0, 0], [1, 1]])\n",
    "y = np.array([0, 1])\n",
    "clf = svm.SVC(gamma='auto')\n",
    "print(clf.fit(X, y))\n",
    "clf.predict([[2,2]])\n",
    "clf.support_vectors_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovo', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multi-class classification\n",
    "# SVC and NuSVC implement multi-class classification in \"one against one\".\n",
    "X = [[0], [1], [2], [3]]\n",
    "Y = [0, 1, 2, 3]\n",
    "clf = svm.SVC(gamma='auto', decision_function_shape='ovo')\n",
    "print(clf.fit(X, Y))\n",
    "dec = clf.decision_function([[1]])   # there are 4*3/2 classifiers\n",
    "clf.decision_function_shape = \"ovr\"  # we can aggregrate them into \"one against rest\", therefore 4 classifiers\n",
    "\n",
    "# LinearSVC implements in \"one against rest\" method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn Logistic Regression\n",
    "Logistic regression is a binary classfication method. Sigmoid function can map $[-\\infty, \\infty]$ to $[0,1]$, which is a deserved property of probability. Therefore:\n",
    "\\begin{equation}\n",
    "\\log\\Big( \\frac{p(x)}{1-p(x)} \\Big) = WX + b\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "p(x) = \\frac{1}{1+exp(-(WX + b))}\n",
    "\\end{equation}\n",
    "\n",
    "To find the optimal coefficients, we can use maximum likelihood estimates. The Log-likelihood is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{L} = \\sum_{i=1}^N y_i log p(x_i) + (1-y_i)log(1-p(x_i))\n",
    "\\end{equation}\n",
    "\n",
    "To find the ML estimates, we need to find $\\frac{\\partial\\mathcal{L}}{\\partial\\theta}=0$. However, this is a transcendental equation, we usually use numerical method to find the solution.\n",
    "\n",
    "### An example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction class: [0 0]\n",
      "with probabilities: [[9.81801790e-01 1.81981959e-02 1.43556907e-08]\n",
      " [9.71727348e-01 2.82726221e-02 3.00307256e-08]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/williamliu/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Three classes classifcation:\n",
    "X,y = load_iris(return_X_y = True)\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='multinomial').fit(X,y)\n",
    "print('Prediction class:',clf.predict(X[:2,:]))\n",
    "print('with probabilities:',clf.predict_proba(X[:2,:]))\n",
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
